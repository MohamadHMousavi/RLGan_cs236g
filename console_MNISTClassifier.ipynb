{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"console_MNISTClassifier.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPdb09qBtRWeI//iZ8G4+l6"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sClNsE7El8wM","executionInfo":{"status":"ok","timestamp":1615690361331,"user_tz":480,"elapsed":1339,"user":{"displayName":"Taha Rajabzadeh","photoUrl":"https://lh6.googleusercontent.com/-ZN4n44MhVrE/AAAAAAAAAAI/AAAAAAAAAA4/mpl3g7Z78WA/s64/photo.jpg","userId":"10185065465507621541"}},"outputId":"8f4623ff-6d8b-47b4-9855-8014690ab592"},"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3HNjIV62l7UG","executionInfo":{"status":"ok","timestamp":1615690361431,"user_tz":480,"elapsed":1410,"user":{"displayName":"Taha Rajabzadeh","photoUrl":"https://lh6.googleusercontent.com/-ZN4n44MhVrE/AAAAAAAAAAI/AAAAAAAAAA4/mpl3g7Z78WA/s64/photo.jpg","userId":"10185065465507621541"}},"outputId":"881d344e-fba6-446c-daff-0419ef6c043b"},"source":["%cd /content/drive/My\\ Drive/courses/Generative\\ Adversial\\ Models_CS236g/RLGan_cs236g/\n","!ls"],"execution_count":2,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/courses/Generative Adversial Models_CS236g/RLGan_cs236g\n","AE_main.py\t\t       logs\n","AE.py\t\t\t       MNIST\n","AE_trainer.py\t\t       MNISTClassifier_main.py\n","checkPoints\t\t       MNISTClassifier.py\n","console_AE.ipynb\t       MNISTClassifier_trainer.py\n","console_gan.ipynb\t       models\n","console_MNISTClassifier.ipynb  papers\n","gan\t\t\t       __pycache__\n","gan_main.py\t\t       README.md\n","gan.py\t\t\t       spectral.py\n","gan_tester.py\t\t       utils.py\n","gan_trainer.py\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bjbUN9084PkX","executionInfo":{"status":"ok","timestamp":1615688574447,"user_tz":480,"elapsed":154451,"user":{"displayName":"Taha Rajabzadeh","photoUrl":"https://lh6.googleusercontent.com/-ZN4n44MhVrE/AAAAAAAAAAI/AAAAAAAAAA4/mpl3g7Z78WA/s64/photo.jpg","userId":"10185065465507621541"}},"outputId":"5c407933-fedc-4037-a7ff-c493620c42fe"},"source":["!python MNISTClassifier_main.py --numEpochs 20 --lr 0.002 --batch_size 1024"],"execution_count":3,"outputs":[{"output_type":"stream","text":["\r  0% 0/59 [00:00<?, ?it/s]/content/drive/My Drive/courses/Generative Adversial Models_CS236g/RLGan_cs236g/MNISTClassifier.py:79: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n","  return F.log_softmax(x)\n"," 34% 20/59 [00:02<00:05,  7.34it/s]Step 20: Classifier loss: 0.2512343369424343\n"," 68% 40/59 [00:05<00:02,  8.32it/s]Step 40: Classifier loss: 0.14662585109472276\n","100% 59/59 [00:07<00:00,  7.68it/s]\n","  2% 1/59 [00:00<00:07,  8.23it/s]Step 60: Classifier loss: 0.12449972108006477\n"," 36% 21/59 [00:02<00:04,  8.12it/s]Step 80: Classifier loss: 0.1135410025715828\n"," 69% 41/59 [00:05<00:02,  6.80it/s]Step 100: Classifier loss: 0.10923559181392192\n","100% 59/59 [00:07<00:00,  7.66it/s]\n","  3% 2/59 [00:00<00:07,  8.09it/s]Step 120: Classifier loss: 0.1056797880679369\n"," 37% 22/59 [00:02<00:04,  8.06it/s]Step 140: Classifier loss: 0.10197998732328414\n"," 71% 42/59 [00:05<00:02,  8.07it/s]Step 160: Classifier loss: 0.10164913199841977\n","100% 59/59 [00:07<00:00,  8.06it/s]\n","  5% 3/59 [00:00<00:08,  6.97it/s]Step 180: Classifier loss: 0.09815317317843437\n"," 39% 23/59 [00:02<00:05,  6.95it/s]Step 200: Classifier loss: 0.09856772199273109\n"," 73% 43/59 [00:05<00:01,  8.03it/s]Step 220: Classifier loss: 0.09660758972167968\n","100% 59/59 [00:07<00:00,  7.76it/s]\n","  7% 4/59 [00:00<00:06,  8.63it/s]Step 240: Classifier loss: 0.09543973542749881\n"," 41% 24/59 [00:02<00:04,  8.32it/s]Step 260: Classifier loss: 0.09483826085925103\n"," 75% 44/59 [00:05<00:02,  7.05it/s]Step 280: Classifier loss: 0.09415286369621753\n","100% 59/59 [00:07<00:00,  8.21it/s]\n","  8% 5/59 [00:00<00:06,  8.32it/s]Step 300: Classifier loss: 0.09297732673585415\n"," 42% 25/59 [00:03<00:04,  7.79it/s]Step 320: Classifier loss: 0.09182398729026317\n"," 76% 45/59 [00:05<00:01,  7.67it/s]Step 340: Classifier loss: 0.09227242395281791\n","100% 59/59 [00:07<00:00,  7.85it/s]\n"," 10% 6/59 [00:00<00:06,  8.14it/s]Step 360: Classifier loss: 0.09235941730439663\n"," 44% 26/59 [00:03<00:04,  7.79it/s]Step 380: Classifier loss: 0.09065566435456276\n"," 78% 46/59 [00:05<00:01,  8.46it/s]Step 400: Classifier loss: 0.08990498483181\n","100% 59/59 [00:07<00:00,  8.04it/s]\n"," 12% 7/59 [00:00<00:06,  8.58it/s]Step 420: Classifier loss: 0.0903990052640438\n"," 46% 27/59 [00:03<00:03,  8.38it/s]Step 440: Classifier loss: 0.08951794542372227\n"," 80% 47/59 [00:05<00:01,  8.06it/s]Step 460: Classifier loss: 0.08968219123780727\n","100% 59/59 [00:07<00:00,  8.24it/s]\n"," 14% 8/59 [00:00<00:06,  8.17it/s]Step 480: Classifier loss: 0.08888318911194801\n"," 47% 28/59 [00:03<00:03,  8.48it/s]Step 500: Classifier loss: 0.0878781445324421\n"," 81% 48/59 [00:05<00:01,  7.93it/s]Step 520: Classifier loss: 0.08823197148740292\n","100% 59/59 [00:07<00:00,  8.20it/s]\n"," 15% 9/59 [00:01<00:07,  6.88it/s]Step 540: Classifier loss: 0.08882169872522354\n"," 49% 29/59 [00:03<00:04,  7.35it/s]Step 560: Classifier loss: 0.0883946519345045\n"," 83% 49/59 [00:06<00:01,  8.42it/s]Step 580: Classifier loss: 0.08773288503289223\n","100% 59/59 [00:07<00:00,  7.87it/s]\n"," 17% 10/59 [00:01<00:06,  7.66it/s]Step 600: Classifier loss: 0.08772399798035621\n"," 51% 30/59 [00:03<00:03,  8.72it/s]Step 620: Classifier loss: 0.08784925639629364\n"," 85% 50/59 [00:06<00:01,  7.24it/s]Step 640: Classifier loss: 0.08705674819648265\n","100% 59/59 [00:07<00:00,  7.93it/s]\n"," 19% 11/59 [00:01<00:05,  8.34it/s]Step 660: Classifier loss: 0.08622081987559796\n"," 53% 31/59 [00:03<00:03,  7.45it/s]Step 680: Classifier loss: 0.08672254048287868\n"," 86% 51/59 [00:06<00:00,  8.03it/s]Step 700: Classifier loss: 0.0869926292449236\n","100% 59/59 [00:07<00:00,  8.11it/s]\n"," 20% 12/59 [00:01<00:05,  8.16it/s]Step 720: Classifier loss: 0.08576125837862492\n"," 54% 32/59 [00:04<00:03,  7.20it/s]Step 740: Classifier loss: 0.08544294573366643\n"," 88% 52/59 [00:06<00:01,  6.79it/s]Step 760: Classifier loss: 0.08646495155990123\n","100% 59/59 [00:07<00:00,  7.56it/s]\n"," 22% 13/59 [00:01<00:06,  7.27it/s]Step 780: Classifier loss: 0.08548822067677975\n"," 56% 33/59 [00:04<00:03,  8.30it/s]Step 800: Classifier loss: 0.08503064662218093\n"," 90% 53/59 [00:06<00:00,  8.00it/s]Step 820: Classifier loss: 0.0857136856764555\n","100% 59/59 [00:07<00:00,  7.84it/s]\n"," 24% 14/59 [00:01<00:05,  8.44it/s]Step 840: Classifier loss: 0.08573539443314075\n"," 58% 34/59 [00:04<00:03,  8.11it/s]Step 860: Classifier loss: 0.084946358948946\n"," 92% 54/59 [00:06<00:00,  8.24it/s]Step 880: Classifier loss: 0.0846809320151806\n","100% 59/59 [00:07<00:00,  8.20it/s]\n"," 25% 15/59 [00:01<00:05,  8.57it/s]Step 900: Classifier loss: 0.08595346584916115\n"," 59% 35/59 [00:04<00:02,  8.18it/s]Step 920: Classifier loss: 0.0845485083758831\n"," 93% 55/59 [00:06<00:00,  7.75it/s]Step 940: Classifier loss: 0.08383215330541134\n","100% 59/59 [00:07<00:00,  8.34it/s]\n"," 27% 16/59 [00:02<00:05,  8.13it/s]Step 960: Classifier loss: 0.0845465250313282\n"," 61% 36/59 [00:04<00:02,  8.50it/s]Step 980: Classifier loss: 0.08499899543821812\n"," 95% 56/59 [00:07<00:00,  8.25it/s]Step 1000: Classifier loss: 0.08417193405330181\n","100% 59/59 [00:07<00:00,  7.85it/s]\n"," 29% 17/59 [00:02<00:05,  8.37it/s]Step 1020: Classifier loss: 0.08479790724813938\n"," 63% 37/59 [00:04<00:02,  8.04it/s]Step 1040: Classifier loss: 0.08367799706757069\n"," 97% 57/59 [00:06<00:00,  8.38it/s]Step 1060: Classifier loss: 0.08446997962892056\n","100% 59/59 [00:06<00:00,  8.44it/s]\n"," 31% 18/59 [00:02<00:04,  8.59it/s]Step 1080: Classifier loss: 0.08408219628036022\n"," 64% 38/59 [00:04<00:02,  8.52it/s]Step 1100: Classifier loss: 0.08375129364430904\n"," 98% 58/59 [00:06<00:00,  8.27it/s]Step 1120: Classifier loss: 0.08364150375127792\n","100% 59/59 [00:07<00:00,  8.39it/s]\n"," 32% 19/59 [00:02<00:04,  8.48it/s]Step 1140: Classifier loss: 0.08377732969820499\n"," 66% 39/59 [00:04<00:02,  8.64it/s]Step 1160: Classifier loss: 0.08349990956485272\n","100% 59/59 [00:06<00:00,  8.52it/s]\n","tensor(98.8900, device='cuda:0')\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"tTE457uwnI40","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615690369625,"user_tz":480,"elapsed":6781,"user":{"displayName":"Taha Rajabzadeh","photoUrl":"https://lh6.googleusercontent.com/-ZN4n44MhVrE/AAAAAAAAAAI/AAAAAAAAAA4/mpl3g7Z78WA/s64/photo.jpg","userId":"10185065465507621541"}},"outputId":"d3f5f362-8fb5-4243-f51d-1c5395726156"},"source":["!python MNISTClassifier_main.py --train false --pretrained_num 20"],"execution_count":3,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/courses/Generative Adversial Models_CS236g/RLGan_cs236g/MNISTClassifier.py:79: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n","  return F.log_softmax(x)\n","tensor(98.8900, device='cuda:0')\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"tQz_As7DobjP"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PIVlHslQocND"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"u0gIsaFvocY2"},"source":[""],"execution_count":null,"outputs":[]}]}